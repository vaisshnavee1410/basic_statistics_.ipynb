{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "O-GW5EGeHwRM"
      ],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaisshnavee1410/basic_statistics_.ipynb/blob/main/Copy_of_Basic_Statistics_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BASIC STATISTICS**"
      ],
      "metadata": {
        "id": "aKu28pvWCxKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descriptive Analysis and Data Preprocessing on Sales & Discount Dataset"
      ],
      "metadata": {
        "id": "jZyOOdVKDW8F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####*Introduction*"
      ],
      "metadata": {
        "id": "I2TIHAZdERG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   To perform descriptive analytics, visualize data distributions, and preprocess the dataset for further analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "YgppiLxDE0IN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Descriptive Analysis for Numerical Columns"
      ],
      "metadata": {
        "id": "kojW3RfhE0de"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Objective: To compute and analyze basic statistical measures for numerical columns in the dataset.\n",
        "*   Steps:\n"
      ],
      "metadata": {
        "id": "TzRmE71eF9e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vaisshnavee1410/basic_statistics_.ipynb.git"
      ],
      "metadata": {
        "id": "MwZh1pSAigxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geopandas"
      ],
      "metadata": {
        "id": "8p0L0WD_jX28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v-M1odh20b6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('sales_data_with_discounts.csv')"
      ],
      "metadata": {
        "id": "wztc90Gi5U96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting numerical columns\n",
        "numerical_cols = ['Volume', 'Avg Price', 'Total Sales Value',\n",
        "                  'Discount Rate (%)', 'Discount Amount', 'Net Sales Value']"
      ],
      "metadata": {
        "id": "PNZ2rEix5pTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute mean, median, standard deviation\n",
        "mean_values = df[numerical_cols].mean()\n",
        "median_values = df[numerical_cols].median()\n",
        "std_values = df[numerical_cols].std()\n",
        "\n"
      ],
      "metadata": {
        "id": "rU3BGsSm-9bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute mode (taking the first mode value)\n",
        "mode_values = df[numerical_cols].mode().iloc[0]"
      ],
      "metadata": {
        "id": "is10Z9uQ_Dt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine results into a single DataFrame\n",
        "stats_df = pd.DataFrame({\n",
        "    'Mean': mean_values,\n",
        "    'Median': median_values,\n",
        "    'Mode': mode_values,\n",
        "    'Standard Deviation': std_values\n",
        "})"
      ],
      "metadata": {
        "id": "qJ-f3J9tAKze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the results\n",
        "print(stats_df)"
      ],
      "metadata": {
        "id": "gIJ1tnP3AYTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Visualization"
      ],
      "metadata": {
        "id": "O-GW5EGeHwRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **Objective:** To visualize the distribution and relationship of numerical and categorical variables in the dataset.\n",
        "*   **Histograms:**\n",
        "\n"
      ],
      "metadata": {
        "id": "qCE7lhpnIGoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import skew"
      ],
      "metadata": {
        "id": "zqZQzqkwIJ32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path = \"sales_data_with_discounts.csv\"\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "71br9auaJnwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify numerical columns\n",
        "numerical_cols = ['Volume', 'Avg Price', 'Total Sales Value',\n",
        "                  'Discount Rate (%)', 'Discount Amount', 'Net Sales Value']"
      ],
      "metadata": {
        "id": "MCoXQrLAKiKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot histograms for all numerical columns\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for i, col in enumerate(numerical_cols, 1):\n",
        "    plt.subplot(2, 3, i)  # Arrange in 2 rows, 3 columns\n",
        "    sns.histplot(df[col], bins=20, kde=True, color='blue')\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f36FGhReKmk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate skewness for each numerical column\n",
        "skewness_values = df[numerical_cols].apply(skew)\n",
        "\n",
        "# Display skewness\n",
        "print(\"\\nSkewness of Each Column:\")\n",
        "print(skewness_values)"
      ],
      "metadata": {
        "id": "_EKTCZAoKzZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create boxplots for all numerical columns\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for i, col in enumerate(numerical_cols, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.boxplot(y=df[col], color='red')\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "    plt.ylabel(col)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hlDUsV_ALrSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpretation of skewness\n",
        "for col in numerical_cols:\n",
        "    skew_value = skewness_values[col]\n",
        "\n",
        "    if skew_value > 1:\n",
        "        skew_type = \"Highly Right-Skewed (Positive Skew)\"\n",
        "    elif 0.5 < skew_value <= 1:\n",
        "        skew_type = \"Moderately Right-Skewed\"\n",
        "    elif -1 < skew_value <= -0.5:\n",
        "        skew_type = \"Moderately Left-Skewed\"\n",
        "    elif skew_value < -1:\n",
        "        skew_type = \"Highly Left-Skewed (Negative Skew)\"\n",
        "    else:\n",
        "        skew_type = \"Approximately Symmetric\"\n",
        "\n",
        "    print(f\"{col}: Skewness = {skew_value:.2f} ({skew_type})\")"
      ],
      "metadata": {
        "id": "HKl6ZXsBMOlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **Boxplots:**\n"
      ],
      "metadata": {
        "id": "j6sep1G4ONOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to detect outliers using IQR\n",
        "def detect_outliers_iqr(data, col):\n",
        "    Q1 = data[col].quantile(0.25)  # First quartile (25th percentile)\n",
        "    Q3 = data[col].quantile(0.75)  # Third quartile (75th percentile)\n",
        "    IQR = Q3 - Q1  # Interquartile Range\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
        "    return outliers"
      ],
      "metadata": {
        "id": "dB2W9-S_OUT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify and print outliers for each numerical column\n",
        "print(\"\\nOutlier Analysis:\")\n",
        "\n",
        "for col in numerical_cols:\n",
        "    outliers = detect_outliers_iqr(df, col)\n",
        "    num_outliers = len(outliers)\n",
        "    print(f\"{col}: {num_outliers} outliers detected.\")"
      ],
      "metadata": {
        "id": "PIx6Dl_VO1qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  **Bar Chart Analysis for Categorical Column:**"
      ],
      "metadata": {
        "id": "PJmWQHHiP2mT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(\"Categorical Columns Identified:\", categorical_cols)"
      ],
      "metadata": {
        "id": "gsX8FYiYQHrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot bar charts for each categorical column\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for i, col in enumerate(categorical_cols[:6], 1):  # Limit to 6 categorical columns for better visualization\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.countplot(y=df[col], palette=\"viridis\", order=df[col].value_counts().index)\n",
        "    plt.title(f'Frequency of {col}')\n",
        "    plt.xlabel(\"Count\")\n",
        "    plt.ylabel(col)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aKm2DlF3Q6Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display category distribution for each categorical column\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\nColumn: {col}\")\n",
        "    print(df[col].value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "id": "bXiUfDEPRNoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xCEzH38llz6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Standardization of Numerical Variables"
      ],
      "metadata": {
        "id": "5Rh0JB5vSEL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **Objective**: To scale numerial variables for uniformity, improving the dataset's suitability for analytical models.\n",
        "\n",
        "\n",
        "*   **Steps:**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l3Um9w-vSfis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "EJ7_TJKOSpIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "_afN52WA9Tzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize each numerical column\n",
        "df_standardized = pd.DataFrame() # Create an empty DataFrame\n",
        "for col in numerical_cols:\n",
        "    mean = df[col].mean()  # Calculate mean (μ)\n",
        "    std_dev = df[col].std()  # Calculate standard deviation (σ)\n",
        "    df_standardized[col] = (df[col] - mean) / std_dev  # Apply Z-score formula\n",
        "\n",
        "\n",
        "# Display first few rows after standardization\n",
        "print(\"Standardized Data Sample:\")\n",
        "df_standardized[numerical_cols].head()"
      ],
      "metadata": {
        "id": "KtMpVgbe90O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparisons of data distributons.\n",
        "\n",
        "fig, axes = plt.subplots(len(numerical_cols), 2, figsize=(12, 4 * len(numerical_cols)))\n",
        "\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    # Original Data Histogram\n",
        "    sns.histplot(df[col], bins=30, kde=True, ax=axes[i, 0], color='blue')\n",
        "    axes[i, 0].set_title(f\"Original Distribution: {col}\")\n",
        "\n",
        "    # Standardized Data Histogram\n",
        "    sns.histplot(df_standardized[col], bins=30, kde=True, ax=axes[i, 1], color='red')\n",
        "    axes[i, 1].set_title(f\"Standardized Distribution: {col}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6N1s4Q9a-BQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Conversion of Categorical Data into Dummy Variables"
      ],
      "metadata": {
        "id": "mfmYiY2CJf1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **Objective:** To transform categorical variables into a format that can be provided to ML algorithms.\n",
        "*   **Steps:**\n"
      ],
      "metadata": {
        "id": "Sywumi_OKK8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "print(\"Categorical Columns Identified:\", categorical_cols)"
      ],
      "metadata": {
        "id": "ljNhlXk4K7K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply One-Hot Encoding\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Display first few rows of transformed data\n",
        "print(\"Data After One-Hot Encoding:\")\n",
        "df_encoded.head()"
      ],
      "metadata": {
        "id": "J2BYD1ltMWhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Conclusion:"
      ],
      "metadata": {
        "id": "4eHabxwFRVT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Summarize the key findings from the descriptive analytics and data visualizations.\n"
      ],
      "metadata": {
        "id": "huxBZ4Z7Re7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After performing descriptive analytics and data visualizations, we have identified several important patterns and insights."
      ],
      "metadata": {
        "id": "mFMdJeK0TXFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descriptive Statistics (Mean, Median, Standard Deviation)\n",
        "\t•\tSales, Discounts, and Quantity sold exhibit high variability, indicating fluctuations across different transactions.\n",
        "\t•\tRight-skewed distributions were observed in sales and discount values, meaning some products had significantly higher sales and discounts than others.\n",
        "\t•\tOutliers were detected, especially in sales and quantity, suggesting promotional impacts or extreme purchasing behavior.\n",
        "\n",
        " Data Distribution (Histograms & Boxplots)\n",
        "\t•\tSales and discount amounts are not normally distributed, with most values concentrated at the lower end.\n",
        "\t•\tOutliers were identified, particularly in sales and discount values, which could indicate seasonal trends, promotional campaigns, or data entry errors.\n",
        "\n",
        "  Bar Charts for Categorical Features\n",
        "\t•\tSome product categories and regions have significantly higher representation than others.\n",
        "\t•\tUneven distribution of sales across different categories suggests that certain products contribute more to total revenue.\n",
        "\n",
        "  One-Hot Encoding Results\n",
        "\t•\tCategorical data was successfully converted into dummy variables, making it suitable for machine learning models.\n",
        "\t•\tSome categories had high cardinality, leading to a larger number of features in the dataset."
      ],
      "metadata": {
        "id": "6-Vs0a7MTeO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Reflect on the importance of data preprocessing steps like standardization\n",
        "and one-hot encoding in data analysis and machine learning\n",
        "\n"
      ],
      "metadata": {
        "id": "q7KfhaMpUYh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Prevents Bias → Standardization avoids dominance of large-scale variables.\n",
        "- Enhances Interpretability → Categorical encoding makes feature relationships clearer.\n",
        "- Required for ML Algorithms → Many models demand properly formatted numerical input.\n",
        "-One-Hot Encoding transformed categorical variables into machine-readable formats, avoiding incorrect interpretations.\n",
        "-Sales & Discount Trends: Sales are highly skewed, with a few high-value transactions contributing significantly to revenue.\n",
        "-Regional & Product Category Insights: Certain regions and product categories dominate, which can guide inventory and marketing strategies.\n",
        "-Preprocessed Data for ML: Standardization and encoding have prepared the dataset for predictive modeling (e.g., sales forecasting, customer segmentation)."
      ],
      "metadata": {
        "id": "z_GAt4KfUnWE"
      }
    }
  ]
}